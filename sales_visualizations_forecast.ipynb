{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Sales Visualizations and Next-Year Forecast (Linear Regression)\n",
        "\n",
        "This notebook:\n",
        "- builds required sales visualizations,\n",
        "- compares **LinearRegression-only** variants,\n",
        "- selects the best out-of-sample model by validation R2,\n",
        "- predicts next-year sales using `REAL_DATA.csv` shifted by +1 year.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import r2_score, mean_absolute_error\n",
        "from sklearn.model_selection import TimeSeriesSplit\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "\n",
        "np.random.seed(42)\n",
        "sns.set_theme(style='whitegrid', context='talk')\n",
        "plt.rcParams['figure.figsize'] = (12, 6)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1) Load and Clean Data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "sales_path = 'data/Copy_of_sales-sales.csv'\n",
        "real_path = 'data/REAL_DATA.csv'\n",
        "\n",
        "sales_df = pd.read_csv(sales_path)\n",
        "real_df = pd.read_csv(real_path)\n",
        "\n",
        "for df in (sales_df, real_df):\n",
        "    for col in ['Unnamed: 0', 'index']:\n",
        "        if col in df.columns:\n",
        "            df.drop(columns=col, inplace=True)\n",
        "\n",
        "sales_df['date'] = pd.to_datetime(sales_df['date'], errors='coerce')\n",
        "real_df['date'] = pd.to_datetime(real_df['date'], dayfirst=True, errors='coerce')\n",
        "\n",
        "required_features = [\n",
        "    'store_ID', 'day_of_week', 'date', 'nb_customers_on_day',\n",
        "    'open', 'promotion', 'state_holiday', 'school_holiday'\n",
        "]\n",
        "\n",
        "missing_sales_features = [c for c in required_features if c not in sales_df.columns]\n",
        "missing_real_features = [c for c in required_features if c not in real_df.columns]\n",
        "assert not missing_sales_features, f'Missing in sales_df: {missing_sales_features}'\n",
        "assert not missing_real_features, f'Missing in real_df: {missing_real_features}'\n",
        "assert 'sales' in sales_df.columns, \"sales target not found in Copy_of_sales-sales.csv\"\n",
        "assert sales_df['sales'].notna().all(), \"sales contains null values\"\n",
        "assert sales_df['date'].notna().all(), \"sales_df date parse produced nulls\"\n",
        "assert real_df['date'].notna().all(), \"real_df date parse produced nulls\"\n",
        "\n",
        "print('sales_df shape:', sales_df.shape)\n",
        "print('real_df shape:', real_df.shape)\n",
        "print('sales date range:', sales_df['date'].min(), 'to', sales_df['date'].max())\n",
        "print('real date range :', real_df['date'].min(), 'to', real_df['date'].max())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2) Shared Feature Engineering\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def add_time_features(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    out = df.copy()\n",
        "    out['year'] = out['date'].dt.year\n",
        "    out['month'] = out['date'].dt.month\n",
        "    out['day'] = out['date'].dt.day\n",
        "    out['weekofyear'] = out['date'].dt.isocalendar().week.astype(int)\n",
        "    out['quarter'] = out['date'].dt.quarter\n",
        "    out['is_weekend'] = out['day_of_week'].isin([6, 7]).astype(int)\n",
        "    out['state_holiday_flag'] = (out['state_holiday'].astype(str) != '0').astype(int)\n",
        "    return out\n",
        "\n",
        "\n",
        "def add_interactions(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    out = df.copy()\n",
        "    out['customers_x_promo'] = out['nb_customers_on_day'] * out['promotion']\n",
        "    out['open_x_promo'] = out['open'] * out['promotion']\n",
        "    out['customers_x_open'] = out['nb_customers_on_day'] * out['open']\n",
        "    return out\n",
        "\n",
        "sales_feat = add_time_features(sales_df)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3) Required Visual: Histogram of Sales by Year\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "yearly_sales = sales_feat.groupby('year', as_index=False)['sales'].sum()\n",
        "print(yearly_sales)\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.histplot(yearly_sales['sales'], bins=8, kde=True, color='steelblue')\n",
        "plt.title('Histogram of Annual Sales Totals')\n",
        "plt.xlabel('Annual Sales')\n",
        "plt.ylabel('Count')\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4) Required Visual: Best Performing Stores Over the Years\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "store_year = sales_feat.groupby(['store_ID', 'year'], as_index=False)['sales'].sum()\n",
        "store_total = store_year.groupby('store_ID', as_index=False)['sales'].sum().sort_values('sales', ascending=False)\n",
        "top10_stores = store_total.head(10)['store_ID']\n",
        "store_year_top10 = store_year[store_year['store_ID'].isin(top10_stores)]\n",
        "\n",
        "plt.figure(figsize=(14, 7))\n",
        "sns.lineplot(data=store_year_top10, x='year', y='sales', hue='store_ID', marker='o')\n",
        "plt.title('Top 10 Stores: Sales Trend Over Years')\n",
        "plt.xlabel('Year')\n",
        "plt.ylabel('Sales')\n",
        "plt.legend(title='Store ID', bbox_to_anchor=(1.02, 1), loc='upper left')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.barplot(data=store_total.head(10), x='store_ID', y='sales', palette='viridis')\n",
        "plt.title('Top 10 Stores by Total Sales')\n",
        "plt.xlabel('Store ID')\n",
        "plt.ylabel('Total Sales')\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5) Modeling: LinearRegression Variants (No Ridge)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "sales_model_df = add_time_features(sales_df)\n",
        "\n",
        "train_df = sales_model_df[sales_model_df['date'] <= pd.Timestamp('2014-12-31')].copy()\n",
        "val_df = sales_model_df[sales_model_df['date'] >= pd.Timestamp('2015-01-01')].copy()\n",
        "assert len(train_df) > 0 and len(val_df) > 0, 'Train/validation split failed.'\n",
        "\n",
        "numeric_base = [\n",
        "    'nb_customers_on_day', 'year', 'month', 'day', 'weekofyear',\n",
        "    'quarter', 'is_weekend'\n",
        "]\n",
        "\n",
        "categorical_cols = [\n",
        "    'store_ID', 'day_of_week', 'open', 'promotion',\n",
        "    'state_holiday', 'school_holiday'\n",
        "]\n",
        "\n",
        "variant_specs = {\n",
        "    'A_numeric_only': {\n",
        "        'numeric': numeric_base + ['store_ID', 'day_of_week', 'open', 'promotion', 'school_holiday', 'state_holiday_flag'],\n",
        "        'categorical': [],\n",
        "        'use_interactions': False,\n",
        "    },\n",
        "    'B_numeric_plus_ohe': {\n",
        "        'numeric': numeric_base,\n",
        "        'categorical': categorical_cols,\n",
        "        'use_interactions': False,\n",
        "    },\n",
        "    'C_plus_interactions': {\n",
        "        'numeric': numeric_base + ['customers_x_promo', 'open_x_promo', 'customers_x_open'],\n",
        "        'categorical': categorical_cols,\n",
        "        'use_interactions': True,\n",
        "    },\n",
        "}\n",
        "\n",
        "results = []\n",
        "trained_models = {}\n",
        "for name, spec in variant_specs.items():\n",
        "    tr = train_df.copy()\n",
        "    va = val_df.copy()\n",
        "    if spec['use_interactions']:\n",
        "        tr = add_interactions(tr)\n",
        "        va = add_interactions(va)\n",
        "\n",
        "    X_train = tr[spec['numeric'] + spec['categorical']]\n",
        "    y_train = tr['sales']\n",
        "    X_val = va[spec['numeric'] + spec['categorical']]\n",
        "    y_val = va['sales']\n",
        "\n",
        "    numeric_transformer = Pipeline([\n",
        "        ('imputer', SimpleImputer(strategy='median')),\n",
        "        ('scaler', StandardScaler()),\n",
        "    ])\n",
        "\n",
        "    if spec['categorical']:\n",
        "        categorical_transformer = Pipeline([\n",
        "            ('imputer', SimpleImputer(strategy='most_frequent')),\n",
        "            ('onehot', OneHotEncoder(handle_unknown='ignore')),\n",
        "        ])\n",
        "        preprocessor = ColumnTransformer([\n",
        "            ('num', numeric_transformer, spec['numeric']),\n",
        "            ('cat', categorical_transformer, spec['categorical']),\n",
        "        ])\n",
        "    else:\n",
        "        preprocessor = ColumnTransformer([\n",
        "            ('num', numeric_transformer, spec['numeric']),\n",
        "        ])\n",
        "\n",
        "    model = Pipeline([\n",
        "        ('preprocessor', preprocessor),\n",
        "        ('regressor', LinearRegression()),\n",
        "    ])\n",
        "\n",
        "    model.fit(X_train, y_train)\n",
        "    val_pred = np.clip(model.predict(X_val), 0, None)\n",
        "    r2 = r2_score(y_val, val_pred)\n",
        "    mae = mean_absolute_error(y_val, val_pred)\n",
        "\n",
        "    results.append({'variant': name, 'r2': r2, 'mae': mae})\n",
        "    trained_models[name] = (model, spec)\n",
        "\n",
        "results_df = pd.DataFrame(results).sort_values('r2', ascending=False).reset_index(drop=True)\n",
        "display(results_df)\n",
        "\n",
        "best_variant = results_df.loc[0, 'variant']\n",
        "best_model, best_spec = trained_models[best_variant]\n",
        "print('Best variant:', best_variant)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6) Validation Diagnostic Plot\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "val_diag = val_df.copy()\n",
        "if best_spec['use_interactions']:\n",
        "    val_diag = add_interactions(val_diag)\n",
        "\n",
        "X_val_best = val_diag[best_spec['numeric'] + best_spec['categorical']]\n",
        "val_diag['pred_sales'] = np.clip(best_model.predict(X_val_best), 0, None)\n",
        "\n",
        "actual_monthly = val_diag.groupby(val_diag['date'].dt.to_period('M'))['sales'].sum().reset_index()\n",
        "pred_monthly = val_diag.groupby(val_diag['date'].dt.to_period('M'))['pred_sales'].sum().reset_index()\n",
        "actual_monthly['date'] = actual_monthly['date'].dt.to_timestamp()\n",
        "pred_monthly['date'] = pred_monthly['date'].dt.to_timestamp()\n",
        "\n",
        "plt.figure(figsize=(13, 6))\n",
        "sns.lineplot(data=actual_monthly, x='date', y='sales', label='Actual', marker='o')\n",
        "sns.lineplot(data=pred_monthly, x='date', y='pred_sales', label='Predicted', marker='o')\n",
        "plt.title('Validation Window: Actual vs Predicted Monthly Sales')\n",
        "plt.xlabel('Month')\n",
        "plt.ylabel('Sales')\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7) Forecast Next Year from REAL_DATA (+1 Year Shift)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "future_df = real_df.copy()\n",
        "future_df['date'] = future_df['date'] + pd.DateOffset(years=1)\n",
        "future_df = add_time_features(future_df)\n",
        "if best_spec['use_interactions']:\n",
        "    future_df = add_interactions(future_df)\n",
        "\n",
        "X_future = future_df[best_spec['numeric'] + best_spec['categorical']]\n",
        "future_df['predicted_sales'] = np.clip(best_model.predict(X_future), 0, None)\n",
        "future_df['year'] = future_df['date'].dt.year\n",
        "\n",
        "forecast_daily = future_df[['store_ID', 'date', 'year', 'predicted_sales']].copy()\n",
        "forecast_yearly = (\n",
        "    forecast_daily\n",
        "    .groupby(['store_ID', 'year'], as_index=False)['predicted_sales']\n",
        "    .sum()\n",
        "    .sort_values('predicted_sales', ascending=False)\n",
        ")\n",
        "\n",
        "forecast_yearly.to_csv('forecast_next_year_linear.csv', index=False)\n",
        "print('Saved forecast_next_year_linear.csv')\n",
        "display(forecast_yearly.head(10))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8) Forecast Visualizations\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "monthly_forecast = (\n",
        "    forecast_daily\n",
        "    .groupby(forecast_daily['date'].dt.to_period('M'))['predicted_sales']\n",
        "    .sum()\n",
        "    .reset_index()\n",
        ")\n",
        "monthly_forecast['date'] = monthly_forecast['date'].dt.to_timestamp()\n",
        "\n",
        "plt.figure(figsize=(13, 6))\n",
        "sns.lineplot(data=monthly_forecast, x='date', y='predicted_sales', marker='o', color='teal')\n",
        "plt.title('Predicted Monthly Sales for Next Year')\n",
        "plt.xlabel('Month')\n",
        "plt.ylabel('Predicted Sales')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "top15 = forecast_yearly.head(15)\n",
        "sns.barplot(data=top15, x='store_ID', y='predicted_sales', palette='magma')\n",
        "plt.title('Top 15 Stores by Predicted Next-Year Sales')\n",
        "plt.xlabel('Store ID')\n",
        "plt.ylabel('Predicted Sales')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.histplot(forecast_daily['predicted_sales'], bins=50, kde=True, color='darkorange')\n",
        "plt.title('Distribution of Daily Predicted Sales (Next Year)')\n",
        "plt.xlabel('Predicted Daily Sales')\n",
        "plt.ylabel('Count')\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9) Extra Useful Visuals\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10, 6))\n",
        "sns.boxplot(data=sales_feat, x='promotion', y='sales')\n",
        "plt.title('Sales Distribution by Promotion Flag')\n",
        "plt.xlabel('Promotion')\n",
        "plt.ylabel('Sales')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "sample_n = min(50000, len(sales_feat))\n",
        "sample_df = sales_feat.sample(sample_n, random_state=42)\n",
        "plt.figure(figsize=(11, 6))\n",
        "sns.regplot(\n",
        "    data=sample_df,\n",
        "    x='nb_customers_on_day',\n",
        "    y='sales',\n",
        "    scatter_kws={'alpha': 0.2, 's': 12},\n",
        "    line_kws={'color': 'red'}\n",
        ")\n",
        "plt.title('Customers vs Sales (Sample)')\n",
        "plt.xlabel('Number of Customers')\n",
        "plt.ylabel('Sales')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "seasonality = (\n",
        "    sales_feat\n",
        "    .groupby(['month', 'day_of_week'], as_index=False)['sales']\n",
        "    .mean()\n",
        "    .pivot(index='month', columns='day_of_week', values='sales')\n",
        ")\n",
        "\n",
        "plt.figure(figsize=(11, 7))\n",
        "sns.heatmap(seasonality, cmap='YlGnBu', annot=False)\n",
        "plt.title('Average Sales Heatmap: Month vs Day of Week')\n",
        "plt.xlabel('Day of Week')\n",
        "plt.ylabel('Month')\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 10) Validation and Sanity Checks\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "orig_dates = real_df['date'].sort_values().reset_index(drop=True)\n",
        "shifted_dates = future_df['date'].sort_values().reset_index(drop=True)\n",
        "delta_days = (shifted_dates - orig_dates).dt.days\n",
        "assert delta_days.isin([365, 366]).all(), 'Shift must be exactly +1 year (365/366 days).'\n",
        "assert {'store_ID', 'year', 'predicted_sales'}.issubset(set(forecast_yearly.columns))\n",
        "assert len(forecast_yearly) > 0\n",
        "assert (forecast_daily['predicted_sales'] >= 0).all()\n",
        "print('All checks passed.')\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Ironhack",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.13.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
